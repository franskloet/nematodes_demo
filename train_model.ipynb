{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/franskloet/nematodes_demo/blob/main/train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of updating existing detector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the files and setup system for colab... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and install torch, torchvision with CUDA support\n",
    "\n",
    "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# install mmcv-full thus we could use CUDA operators\n",
    "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
    "\n",
    "# Install mmdetection\n",
    "!rm -rf mmdetection\n",
    "!git clone https://github.com/open-mmlab/mmdetection.git\n",
    "%cd mmdetection\n",
    "\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the weights of a pre-trained network\n",
    "!mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth \\\n",
    "      -O ./checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download some images formatted for training\n",
    "!rm -rf mm_images\n",
    "!git clone https://github.com/franskloet/mm_images.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "import base64\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the configuration file direct from the github repository .. \n",
    "config_file_url = 'https://api.github.com/repos/franskloet/nematodes_demo/contents/hatched_juvenile_config.py'\n",
    "response = requests.get(config_file_url)\n",
    "req = response.json()\n",
    "open('hatched_juvenile_config_inet.py',\"wb\").write(base64.decodebytes(bytes(req['content'], 'utf-8')))\n",
    "config_file = './hatched_juvenile_config_inet.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import torch\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.runner import get_dist_info, init_dist\n",
    "from mmcv.utils import get_git_hash\n",
    "\n",
    "from mmdet import __version__\n",
    "from mmdet.apis import init_random_seed, set_random_seed, train_detector\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.utils import collect_env, get_root_logger, setup_multi_processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parser function for setting program defaults \n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Train a detector')\n",
    "    parser.add_argument('config', help='train config file path')\n",
    "    parser.add_argument('--work-dir', help='the dir to save logs and models')\n",
    "    parser.add_argument(\n",
    "        '--resume-from', help='the checkpoint file to resume from')\n",
    "    parser.add_argument(\n",
    "        '--auto-resume',\n",
    "        action='store_true',\n",
    "        help='resume from the latest checkpoint automatically')\n",
    "    parser.add_argument(\n",
    "        '--no-validate',\n",
    "        action='store_true',\n",
    "        help='whether not to evaluate the checkpoint during training')\n",
    "    group_gpus = parser.add_mutually_exclusive_group()\n",
    "    group_gpus.add_argument(\n",
    "        '--gpus',\n",
    "        type=int,\n",
    "        help='(Deprecated, please use --gpu-id) number of gpus to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    group_gpus.add_argument(\n",
    "        '--gpu-ids',\n",
    "        type=int,\n",
    "        nargs='+',\n",
    "        help='(Deprecated, please use --gpu-id) ids of gpus to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    group_gpus.add_argument(\n",
    "        '--gpu-id',\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help='id of gpu to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    parser.add_argument('--seed', type=int, default=None, help='random seed')\n",
    "    parser.add_argument(\n",
    "        '--deterministic',\n",
    "        action='store_true',\n",
    "        help='whether to set deterministic options for CUDNN backend.')\n",
    "    parser.add_argument(\n",
    "        '--options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        help='override some settings in the used config, the key-value pair '\n",
    "        'in xxx=yyy format will be merged into config file (deprecate), '\n",
    "        'change to --cfg-options instead.')\n",
    "    parser.add_argument(\n",
    "        '--cfg-options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        help='override some settings in the used config, the key-value pair '\n",
    "        'in xxx=yyy format will be merged into config file. If the value to '\n",
    "        'be overwritten is a list, it should be like key=\"[a,b]\" or key=a,b '\n",
    "        'It also allows nested list/tuple values, e.g. key=\"[(a,b),(c,d)]\" '\n",
    "        'Note that the quotation marks are necessary and that no white space '\n",
    "        'is allowed.')\n",
    "    parser.add_argument(\n",
    "        '--launcher',\n",
    "        choices=['none', 'pytorch', 'slurm', 'mpi'],\n",
    "        default='none',\n",
    "        help='job launcher')\n",
    "    parser.add_argument('--local_rank', type=int, default=0)\n",
    "    args = parser.parse_args()\n",
    "    if 'LOCAL_RANK' not in os.environ:\n",
    "        os.environ['LOCAL_RANK'] = str(args.local_rank)\n",
    "\n",
    "    if args.options and args.cfg_options:\n",
    "        raise ValueError(\n",
    "            '--options and --cfg-options cannot be both '\n",
    "            'specified, --options is deprecated in favor of --cfg-options')\n",
    "    if args.options:\n",
    "        warnings.warn('--options is deprecated in favor of --cfg-options')\n",
    "        args.cfg_options = args.options\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse config file and configure application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['script.py',config_file]\n",
    "args = parse_args()\n",
    "\n",
    "cfg = Config.fromfile(args.config)\n",
    "\n",
    "if args.cfg_options is not None:\n",
    "    cfg.merge_from_dict(args.cfg_options)\n",
    "\n",
    "# set multi-process settings\n",
    "setup_multi_processes(cfg)\n",
    "\n",
    "# set cudnn_benchmark\n",
    "if cfg.get('cudnn_benchmark', False):\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# work_dir is determined in this priority: CLI > segment in file > filename\n",
    "if args.work_dir is not None:\n",
    "    # update configs according to CLI args if args.work_dir is not None\n",
    "    cfg.work_dir = args.work_dir\n",
    "elif cfg.get('work_dir', None) is None:\n",
    "    # use config filename as default work_dir if cfg.work_dir is None\n",
    "    cfg.work_dir = osp.join('./work_dirs',\n",
    "                            osp.splitext(osp.basename(args.config))[0])\n",
    "if args.resume_from is not None:\n",
    "    cfg.resume_from = args.resume_from\n",
    "cfg.auto_resume = args.auto_resume\n",
    "if args.gpus is not None:\n",
    "    cfg.gpu_ids = range(1)\n",
    "    warnings.warn('`--gpus` is deprecated because we only support '\n",
    "                  'single GPU mode in non-distributed training. '\n",
    "                  'Use `gpus=1` now.')\n",
    "if args.gpu_ids is not None:\n",
    "    cfg.gpu_ids = args.gpu_ids[0:1]\n",
    "    warnings.warn('`--gpu-ids` is deprecated, please use `--gpu-id`. '\n",
    "                  'Because we only support single GPU mode in '\n",
    "                  'non-distributed training. Use the first GPU '\n",
    "                  'in `gpu_ids` now.')\n",
    "if args.gpus is None and args.gpu_ids is None:\n",
    "    cfg.gpu_ids = [args.gpu_id]\n",
    "\n",
    "# init distributed env first, since logger depends on the dist info.\n",
    "if args.launcher == 'none':\n",
    "    distributed = False\n",
    "else:\n",
    "    distributed = True\n",
    "    init_dist(args.launcher, **cfg.dist_params)\n",
    "    # re-set gpu_ids with distributed training mode\n",
    "    _, world_size = get_dist_info()\n",
    "    cfg.gpu_ids = range(world_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "# dump config\n",
    "cfg.dump(osp.join(cfg.work_dir, osp.basename(config_file)))\n",
    "# init the logger before other steps\n",
    "timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
    "log_file = osp.join(cfg.work_dir, f'{timestamp}.log')\n",
    "logger = get_root_logger(log_file=log_file, log_level=cfg.log_level)\n",
    "\n",
    "# init the meta dict to record some important information such as\n",
    "# environment info and seed, which will be logged\n",
    "\n",
    "meta = dict()\n",
    "# log env info\n",
    "env_info_dict = collect_env()\n",
    "env_info = '\\n'.join([(f'{k}: {v}') for k, v in env_info_dict.items()])\n",
    "dash_line = '-' * 60 + '\\n'\n",
    "logger.info('Environment info:\\n' + dash_line + env_info + '\\n' +\n",
    "            dash_line)\n",
    "meta['env_info'] = env_info\n",
    "meta['config'] = cfg.pretty_text\n",
    "# log some basic info\n",
    "logger.info(f'Distributed training: {distributed}')\n",
    "logger.info(f'Config:\\n{cfg.pretty_text}')\n",
    "\n",
    "# set random seeds\n",
    "seed = init_random_seed(args.seed)\n",
    "logger.info(f'Set random seed to {seed}, '\n",
    "            f'deterministic: {args.deterministic}')\n",
    "set_random_seed(seed, deterministic=args.deterministic)\n",
    "cfg.seed = seed\n",
    "meta['seed'] = seed\n",
    "meta['exp_name'] = osp.basename(args.config)\n",
    "\n",
    "model = build_detector(\n",
    "    cfg.model,\n",
    "    train_cfg=cfg.get('train_cfg'),\n",
    "    test_cfg=cfg.get('test_cfg'))\n",
    "model.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if CUDA is supported \n",
    "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
    "print('Device:', torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device to cuda to use GPU and to cpu to run on CPU only\n",
    "cfg.device='cuda'\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "if len(cfg.workflow) == 2:\n",
    "    val_dataset = copy.deepcopy(cfg.data.val)\n",
    "    val_dataset.pipeline = cfg.data.train.pipeline\n",
    "    datasets.append(build_dataset(val_dataset))\n",
    "if cfg.checkpoint_config is not None:\n",
    "    # save mmdet version, config file content and class names in\n",
    "    # checkpoints as meta data\n",
    "    cfg.checkpoint_config.meta = dict(\n",
    "        mmdet_version=__version__ + get_git_hash()[:7],\n",
    "        CLASSES=datasets[0].CLASSES)\n",
    "# add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "train_detector(\n",
    "    model,\n",
    "    datasets,\n",
    "    cfg,\n",
    "    distributed=distributed,\n",
    "    validate=(not args.no_validate),\n",
    "    timestamp=timestamp,\n",
    "    meta=meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the results to your local google drive..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authorize colab to connect to your google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the files.. needed for prediction in external notebook\n",
    "!cp ./work_dir/juvenile_hatched_unhatched_b_3/epoch_500.pth /content/drive/MyDrive/Colab\\ Notebooks/results\n",
    "!cp ./work_dir/juvenile_hatched_unhatched_b_3/hatched_juvenile_config_inet.py /content/drive/MyDrive/Colab\\ Notebooks/results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example prediction from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the proper model\n",
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "\n",
    "# Choose to use a config and initialize the detector\n",
    "config = './work_dir/juvenile_hatched_unhatched_b_3/hatched_juvenile_config_inet.py'\n",
    "checkpoint = './work_dir/juvenile_hatched_unhatched_b_3/epoch_500.pth' \n",
    "\n",
    "model = init_detector(config, checkpoint, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect the image\n",
    "img = \"./mm_images/test/images/180704_Gros_F4.tiff\"\n",
    "img = \"./mm_images/test/images/200224_C7.tif\"\n",
    "img = \"./mm_images/test/images/200310_C3.tif\"\n",
    "result = inference_detector(model, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show the resulting image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the higher the score_thr the more sure the classifaction result\n",
    "show_result_pyplot(model, img, result, score_thr=0.15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('openmmlab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de567cb796dc419393a341152dc66488936f56834bf76c5f839c2c2fd536bffe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
